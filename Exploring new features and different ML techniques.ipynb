{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from datetime import date\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.cross_validation import ShuffleSplit\n",
    "from sklearn.ensemble import (\n",
    "    GradientBoostingRegressor,\n",
    "    RandomForestRegressor,\n",
    "    ExtraTreesRegressor,\n",
    ")\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.core import (\n",
    "    Dense,\n",
    "    Dropout,\n",
    "    Activation,\n",
    "    Merge, \n",
    "    Reshape\n",
    ")\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from metric import rmsle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create basic datetime features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_period(timestamp):\n",
    "    initial_date = date(2011, 1, 1)\n",
    "    current_date = timestamp.date()\n",
    "    return (current_date.year - initial_date.year) * 12 + (current_date.month - initial_date.month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv', parse_dates=['datetime'])\n",
    "\n",
    "def create_datetime_features(df):\n",
    "    df['month'] = df.datetime.map(lambda ts: ts.date().month)\n",
    "    df['week_day'] = df.datetime.map(lambda ts: ts.date().isoweekday())\n",
    "    df['week_number'] = df.datetime.map(lambda ts: ts.date().isocalendar()[1])\n",
    "    df['hour'] = df.datetime.map(lambda ts: ts.hour)\n",
    "    df['year'] = df.datetime.map(lambda ts: ts.date().year) \n",
    "    return df\n",
    "\n",
    "df = create_datetime_features(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try Grandient Boost with ShuffleSplit - CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "possible_features = [\n",
    "    'season', 'holiday', 'workingday', 'weather', \n",
    "    'temp', 'atemp', 'windspeed', 'month', \n",
    "    'hour', 'year', 'week_day']\n",
    "target = 'count'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.619339109963 +/- 0.0203670517485\n"
     ]
    }
   ],
   "source": [
    "model = GradientBoostingRegressor()\n",
    "results = []\n",
    "for train_idx, test_idx in ShuffleSplit(len(df), n_iter=10, test_size=0.3):\n",
    "    model.fit(df.iloc[train_idx][possible_features], df.iloc[train_idx][target])\n",
    "    y_pred = model.predict(df.iloc[test_idx][possible_features])\n",
    "    y_true =  df.iloc[test_idx][target]\n",
    "    results.append(rmsle(y_pred, y_true))\n",
    "print np.mean(results), \"+/-\", np.std(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add Log Scaled Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['log_count'] = np.log1p(df['count'])\n",
    "df['log_registered'] = np.log1p(df['registered'])\n",
    "df['log_casual'] = np.log1p(df['casual'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.389355593927 +/- 0.00936657387187\n"
     ]
    }
   ],
   "source": [
    "model = GradientBoostingRegressor()\n",
    "results = []\n",
    "for train_idx, test_idx in ShuffleSplit(len(df), n_iter=10, test_size=0.3):\n",
    "    model.fit(df.iloc[train_idx][possible_features], df.iloc[train_idx]['log_count'])\n",
    "    y_pred = model.predict(df.iloc[test_idx][possible_features])\n",
    "    y_true =  df.iloc[test_idx][target]\n",
    "    results.append(rmsle(np.expm1(y_pred), y_true))\n",
    "print np.mean(results), \"+/-\", np.std(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better ;)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add period & week day feature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['period'] = df.datetime.map(calculate_period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.322041547746 +/- 0.0033472935359\n"
     ]
    }
   ],
   "source": [
    "possible_features = [\n",
    "    'season', 'holiday', 'workingday', 'weather', \n",
    "    'temp', 'atemp', 'windspeed', 'month', 'hour', 'year',\n",
    "    'period', 'week_day']\n",
    "\n",
    "model = GradientBoostingRegressor(n_estimators=200)\n",
    "results = []\n",
    "for train_idx, test_idx in ShuffleSplit(len(df), n_iter=10, test_size=0.3):\n",
    "    model.fit(df.iloc[train_idx][possible_features], df.iloc[train_idx]['log_count'])\n",
    "    y_pred = np.expm1(model.predict(df.iloc[test_idx][possible_features]))\n",
    "    y_true =  df.iloc[test_idx][target]\n",
    "    results.append(rmsle(y_pred, y_true))\n",
    "print np.mean(results), \"+/-\", np.std(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check split into registered prediction and causal prediction + change to Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.306949120888 +/- 0.0077058747834\n"
     ]
    }
   ],
   "source": [
    "possible_features = [\n",
    "    'season', 'holiday', 'workingday', 'weather', 'temp', 'atemp', \n",
    "    'windspeed', 'month', 'hour', 'year', 'period', 'week_day'\n",
    "]\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=200, n_jobs=4)\n",
    "results = []\n",
    "for train_idx, test_idx in ShuffleSplit(len(df), n_iter=10, test_size=0.3):\n",
    "    model.fit(df.iloc[train_idx][possible_features], df.iloc[train_idx]['log_registered'])\n",
    "    reg_pred = np.expm1(model.predict(df.iloc[test_idx][possible_features]))\n",
    "    \n",
    "    model.fit(df.iloc[train_idx][possible_features], df.iloc[train_idx]['log_casual'])\n",
    "    cas_pred = np.expm1(model.predict(df.iloc[test_idx][possible_features]))\n",
    "  \n",
    "    y_pred = reg_pred + cas_pred\n",
    "    y_true =  df.iloc[test_idx][target]\n",
    "    results.append(rmsle(y_pred, y_true))\n",
    "print np.mean(results), \"+/-\", np.std(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try new represenation -- Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w_embedding_model = Sequential()\n",
    "w_embedding_model.add(Embedding(10, 1, input_length=6))\n",
    "w_embedding_model.add(Reshape(target_shape=(6,)))\n",
    "w_embedding_model.compile('rmsprop', 'msle')\n",
    "\n",
    "wd_embedding_model = Sequential()\n",
    "wd_embedding_model.add(Embedding(10, 1, input_length=6))\n",
    "wd_embedding_model.add(Reshape(target_shape=(6,)))\n",
    "wd_embedding_model.compile('rmsprop', 'msle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weather_gp = df.groupby(['weather'])['log_count', 'log_registered', 'log_casual']\n",
    "weather_agg_df = weather_gp.mean().merge(\n",
    "    weather_gp.median(), suffixes=('_mean', '_median'), left_index=True, right_index=True)\n",
    "\n",
    "week_day_gp = df.groupby(['week_day'])['log_count', 'log_registered', 'log_casual']\n",
    "week_day_agg_df = week_day_gp.mean().merge(\n",
    "    week_day_gp.median(), suffixes=('_mean', '_median'), left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weather_features = w_embedding_model.predict(weather_agg_df.values)\n",
    "week_day_features = wd_embedding_model.predict(week_day_agg_df.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.04401053,  0.04401053,  0.03068844, -0.03055367,  0.04401053,\n",
       "         0.03695909],\n",
       "       [ 0.04401053,  0.04401053,  0.03068844,  0.04401053,  0.04401053,\n",
       "         0.03068844],\n",
       "       [ 0.04401053,  0.03695909,  0.02493496,  0.04401053,  0.04401053,\n",
       "         0.02493496],\n",
       "       [-0.03055367, -0.03055367,  0.02493496, -0.03055367, -0.03055367,\n",
       "         0.02493496]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "clf = PCA(3)\n",
    "weather_features = clf.fit_transform(weather_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.04429511,  0.04429511, -0.03744267,  0.04429511,  0.04429511,\n",
       "        -0.03744267],\n",
       "       [ 0.04429511,  0.04429511, -0.03744267,  0.04429511,  0.04429511,\n",
       "        -0.03744267],\n",
       "       [ 0.04429511,  0.04429511, -0.03744267,  0.04429511,  0.04429511,\n",
       "        -0.03744267],\n",
       "       [ 0.04429511,  0.04429511, -0.03744267, -0.04366054,  0.04429511,\n",
       "        -0.03744267],\n",
       "       [ 0.04429511,  0.04429511, -0.03744267, -0.04366054,  0.04429511,\n",
       "        -0.03744267],\n",
       "       [ 0.04429511,  0.04429511, -0.03815959,  0.04429511,  0.04429511,\n",
       "        -0.03815959],\n",
       "       [ 0.04429511,  0.04429511, -0.03815959,  0.04429511,  0.04429511,\n",
       "        -0.03815959]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "week_day_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = PCA(3)\n",
    "week_day_features = clf.fit_transform(week_day_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weather_columns = ['weather_{}'.format(i) for i in range(weather_features.shape[1])]\n",
    "df_weather = pd.DataFrame(index=weather_agg_df.index).reset_index().join(pd.DataFrame(weather_features, columns=weather_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "week_day_columns = ['week_day_{}'.format(i) for i in range(week_day_features.shape[1])]\n",
    "df_week_day = pd.DataFrame(index=week_day_agg_df.index).reset_index().join(pd.DataFrame(week_day_features, columns=week_day_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "merged_df = df.merge(df_weather, on=['weather'])\n",
    "merged_df = merged_df.merge(df_week_day, on=['week_day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.326291054463 +/- 0.00667505717805\n"
     ]
    }
   ],
   "source": [
    "possible_features = [\n",
    "    'season', 'holiday', 'workingday', 'temp', 'atemp', \n",
    "    'windspeed', 'month', 'hour', 'year', 'period',\n",
    "] + weather_columns + weather_columns\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=200, n_jobs=4)\n",
    "results = []\n",
    "for train_idx, test_idx in ShuffleSplit(len(df), n_iter=10, test_size=0.3):\n",
    "    model.fit(merged_df.iloc[train_idx][possible_features], merged_df.iloc[train_idx]['log_registered'])\n",
    "    reg_pred = np.expm1(model.predict(merged_df.iloc[test_idx][possible_features]))\n",
    "    \n",
    "    model.fit(merged_df.iloc[train_idx][possible_features], merged_df.iloc[train_idx]['log_casual'])\n",
    "    cas_pred = np.expm1(model.predict(merged_df.iloc[test_idx][possible_features]))\n",
    "  \n",
    "    y_pred = reg_pred + cas_pred\n",
    "    y_true =  merged_df.iloc[test_idx][target]\n",
    "    results.append(rmsle(y_pred, y_true))\n",
    "print np.mean(results), \"+/-\", np.std(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.310750455874 +/- 0.00657877016079\n"
     ]
    }
   ],
   "source": [
    "possible_features = [\n",
    "    'season', 'holiday', 'workingday', 'temp', 'atemp', \n",
    "    'windspeed', 'month', 'hour', 'year', 'period', 'week_day'\n",
    "] + weather_columns \n",
    "\n",
    "model = RandomForestRegressor(n_estimators=200, n_jobs=4)\n",
    "results = []\n",
    "for train_idx, test_idx in ShuffleSplit(len(df), n_iter=10, test_size=0.3):\n",
    "    model.fit(merged_df.iloc[train_idx][possible_features], merged_df.iloc[train_idx]['log_registered'])\n",
    "    reg_pred = np.expm1(model.predict(merged_df.iloc[test_idx][possible_features]))\n",
    "    \n",
    "    model.fit(merged_df.iloc[train_idx][possible_features], merged_df.iloc[train_idx]['log_casual'])\n",
    "    cas_pred = np.expm1(model.predict(merged_df.iloc[test_idx][possible_features]))\n",
    "  \n",
    "    y_pred = reg_pred + cas_pred\n",
    "    y_true =  merged_df.iloc[test_idx][target]\n",
    "    results.append(rmsle(y_pred, y_true))\n",
    "print np.mean(results), \"+/-\", np.std(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.321277397046 +/- 0.00438124311109\n"
     ]
    }
   ],
   "source": [
    "possible_features = [\n",
    "    'season', 'holiday', 'workingday', 'weather', 'temp', 'atemp', \n",
    "    'windspeed', 'month', 'hour', 'year', 'period',\n",
    "] +  week_day_columns\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=200, n_jobs=4)\n",
    "results = []\n",
    "for train_idx, test_idx in ShuffleSplit(len(df), n_iter=10, test_size=0.3):\n",
    "    model.fit(merged_df.iloc[train_idx][possible_features], merged_df.iloc[train_idx]['log_registered'])\n",
    "    reg_pred = np.expm1(model.predict(merged_df.iloc[test_idx][possible_features]))\n",
    "    \n",
    "    model.fit(merged_df.iloc[train_idx][possible_features], merged_df.iloc[train_idx]['log_casual'])\n",
    "    cas_pred = np.expm1(model.predict(merged_df.iloc[test_idx][possible_features]))\n",
    "  \n",
    "    y_pred = reg_pred + cas_pred\n",
    "    y_true =  merged_df.iloc[test_idx][target]\n",
    "    results.append(rmsle(y_pred, y_true))\n",
    "print np.mean(results), \"+/-\", np.std(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It does not look very helpful :("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try simple deep learning techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "possible_features = ['holiday', 'weather', 'temp', 'atemp', 'windspeed', 'month', 'hour', 'year', 'period', 'week_day']\n",
    "\n",
    "indexes = np.random.permutation(len(merged_df))\n",
    "test_indexes = indexes[:int(len(merged_df) * 0.3)]\n",
    "train_indexes = indexes[int(len(merged_df) * 0.3):]\n",
    "\n",
    "X = merged_df[possible_features].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model(input_dim):\n",
    "    model = Sequential()\n",
    "    model.add(BatchNormalization(input_shape=(input_dim, )))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(5, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mae', optimizer='sgd')\n",
    "    return model    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.74341005558447182"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = create_model(len(possible_features))\n",
    "model.fit(\n",
    "    X[train_indexes],\n",
    "    merged_df.iloc[train_indexes][['log_count']].values,\n",
    "    batch_size=100, nb_epoch=1000,\n",
    "    verbose=0,\n",
    "    validation_data=(X[test_indexes], merged_df.iloc[test_indexes][['log_count']].values),\n",
    "    callbacks=[EarlyStopping(verbose=0, patience=50)],\n",
    ")\n",
    "rmsle(np.expm1(model.predict(X[test_indexes]).ravel()), merged_df.iloc[test_indexes][target].ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it needs more exploration..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try removing some features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.309681241524 +/- 0.00889556768212\n"
     ]
    }
   ],
   "source": [
    "possible_features = [\n",
    "    'season', 'holiday', 'weather', 'temp', 'atemp', \n",
    "    'windspeed', 'month', 'hour', 'year', 'period', 'week_day'\n",
    "]\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=200, n_jobs=4)\n",
    "results = []\n",
    "for train_idx, test_idx in ShuffleSplit(len(df), n_iter=10, test_size=0.3):\n",
    "    model.fit(df.iloc[train_idx][possible_features], df.iloc[train_idx]['log_registered'])\n",
    "    reg_pred = np.expm1(model.predict(df.iloc[test_idx][possible_features]))\n",
    "    \n",
    "    model.fit(df.iloc[train_idx][possible_features], df.iloc[train_idx]['log_casual'])\n",
    "    cas_pred = np.expm1(model.predict(df.iloc[test_idx][possible_features]))\n",
    "  \n",
    "    y_pred = reg_pred + cas_pred\n",
    "    y_true =  df.iloc[test_idx][target]\n",
    "    results.append(rmsle(y_pred, y_true))\n",
    "print np.mean(results), \"+/-\", np.std(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.304904836797 +/- 0.00634309303924\n"
     ]
    }
   ],
   "source": [
    "possible_features = [\n",
    "    'holiday', 'workingday', 'weather', 'temp', 'atemp', \n",
    "    'windspeed', 'month', 'hour', 'year', 'period', 'week_day'\n",
    "]\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=200, n_jobs=4)\n",
    "results = []\n",
    "for train_idx, test_idx in ShuffleSplit(len(df), n_iter=10, test_size=0.3):\n",
    "    model.fit(df.iloc[train_idx][possible_features], df.iloc[train_idx]['log_registered'])\n",
    "    reg_pred = np.expm1(model.predict(df.iloc[test_idx][possible_features]))\n",
    "    \n",
    "    model.fit(df.iloc[train_idx][possible_features], df.iloc[train_idx]['log_casual'])\n",
    "    cas_pred = np.expm1(model.predict(df.iloc[test_idx][possible_features]))\n",
    "  \n",
    "    y_pred = reg_pred + cas_pred\n",
    "    y_true =  df.iloc[test_idx][target]\n",
    "    results.append(rmsle(y_pred, y_true))\n",
    "print np.mean(results), \"+/-\", np.std(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.308603065611 +/- 0.00768300734267\n"
     ]
    }
   ],
   "source": [
    "possible_features = [\n",
    "    'holiday', 'workingday', 'weather', 'atemp', \n",
    "    'windspeed', 'month', 'hour', 'year', 'period', 'week_day'\n",
    "]\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=200, n_jobs=4)\n",
    "results = []\n",
    "for train_idx, test_idx in ShuffleSplit(len(df), n_iter=10, test_size=0.3):\n",
    "    model.fit(df.iloc[train_idx][possible_features], df.iloc[train_idx]['log_registered'])\n",
    "    reg_pred = np.expm1(model.predict(df.iloc[test_idx][possible_features]))\n",
    "    \n",
    "    model.fit(df.iloc[train_idx][possible_features], df.iloc[train_idx]['log_casual'])\n",
    "    cas_pred = np.expm1(model.predict(df.iloc[test_idx][possible_features]))\n",
    "  \n",
    "    y_pred = reg_pred + cas_pred\n",
    "    y_true =  df.iloc[test_idx][target]\n",
    "    results.append(rmsle(y_pred, y_true))\n",
    "print np.mean(results), \"+/-\", np.std(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate current best solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('test.csv', parse_dates=['datetime'])\n",
    "test_df = create_datetime_features(test_df)\n",
    "test_df['period'] = test_df.datetime.map(calculate_period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "possible_features = [\n",
    "    'holiday', 'workingday', 'weather', 'temp', 'atemp', \n",
    "    'windspeed', 'month', 'hour', 'year', 'period', 'week_day'\n",
    "]\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=200, n_jobs=4)\n",
    "\n",
    "# shuffle dataset\n",
    "df = df.iloc[np.random.permutation(len(df))].reset_index(drop=True)\n",
    "\n",
    "model.fit(df[possible_features], df['log_registered'])\n",
    "reg_pred = np.expm1(model.predict(test_df[possible_features]))\n",
    "\n",
    "model.fit(df[possible_features], df['log_casual'])\n",
    "cas_pred = np.expm1(model.predict(test_df[possible_features]))\n",
    "\n",
    "y_pred = reg_pred + cas_pred\n",
    "pd.DataFrame(\n",
    "    {'datetime': test_df.datetime, 'count': y_pred}\n",
    ")[['datetime', 'count']].to_csv('my_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paramter tuning is written as a script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
